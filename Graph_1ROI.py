#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# (Same logic, updated defaults and discovery)

import argparse
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import numpy as np
import pandas as pd
import nibabel as nib

# ... (Include the quantiles helper and other funcs from before) ...
# I will output the FULL file to ensure you have the updated paths.

def _quantiles(vals: np.ndarray, qs: List[float]) -> np.ndarray:
    vals = np.asarray(vals, dtype=np.float32)
    try:
        return np.quantile(vals, qs, method="linear")
    except TypeError:
        return np.quantile(vals, qs, interpolation="linear")

def load_label_table(csv_path: Path) -> Dict[int, str]:
    df = pd.read_csv(csv_path)
    if "id" not in df.columns or "name" not in df.columns:
        raise ValueError(f"Table columns error: {list(df.columns)}")
    mapping = {}
    for _, row in df.iterrows():
        try:
            i = int(row["id"])
            name = str(row["name"]).strip()
            if name: mapping[i] = name
        except Exception: continue
    return mapping

def label_name_from_id(roi_id, id_to_name, lr_offset, right_suffix, left_suffix):
    if roi_id == 0: return 0, "", "Background"
    if lr_offset > 0 and roi_id >= lr_offset:
        base_id = roi_id - lr_offset; side = "L"
        full = f"{id_to_name.get(base_id, f'ID_{base_id}')}{left_suffix}"
    else:
        base_id = roi_id; side = "R"
        full = f"{id_to_name.get(base_id, f'ID_{base_id}')}{right_suffix}"
    return base_id, side, full

def discover_templates(out_root: Path, modalities: List[str]) -> List[Tuple[str, str, Path]]:
    """
    New logic: 
    1. Check derivatives/templates/<GROUP>/<MODALITY>/res-0.1mm/*.nii.gz (created by Rare_Template)
    2. Check derivatives/Brain_extracted/<MODALITY>/To_Template/<GROUP>/template/*.nii.gz (created by Make_Template)
    """
    found = []
    
    # Check 1: Templates generated by Rare_Template (clean structure)
    tmpl_root = out_root / "derivatives" / "templates"
    if tmpl_root.is_dir():
        for group_dir in tmpl_root.iterdir():
            if not group_dir.is_dir(): continue
            group = group_dir.name
            for mod in modalities:
                # Look in res-0.1mm
                target = group_dir / mod / "res-0.1mm" / f"{group}_{mod}_template.nii.gz"
                if target.exists():
                    found.append((group, mod, target))

    # Check 2: Averages generated by Make_Template (legacy structure inside Brain_extracted)
    for m in modalities:
        base = out_root / "derivatives" / "Brain_extracted" / m / "To_Template"
        if not base.is_dir(): continue
        for group_dir in base.iterdir():
            if not group_dir.is_dir(): continue
            group = group_dir.name
            target = group_dir / "template" / f"{group}_{m}_template.nii.gz"
            if target.exists():
                # Avoid duplicates if found in both (rare case)
                if not any(f[0]==group and f[1]==m for f in found):
                    found.append((group, m, target))
    return found

def compute_stats_fast(label_data, value_data, include_negative, compute_minmax):
    # ... (Same math logic as before) ...
    labels = label_data.astype(np.int32).ravel()
    values = value_data.astype(np.float32).ravel()
    mask = np.isfinite(values)
    if not include_negative: mask &= (values >= 0)
    labels = labels[mask]; values = values[mask]
    if labels.size == 0: return {}
    max_label = int(labels.max())
    counts = np.bincount(labels, minlength=max_label + 1).astype(np.int64)
    sums = np.bincount(labels, weights=values, minlength=max_label + 1).astype(np.float64)
    sums2 = np.bincount(labels, weights=(values * values), minlength=max_label + 1).astype(np.float64)
    with np.errstate(divide="ignore", invalid="ignore"):
        means = sums / counts
        vars_ = (sums2 / counts) - (means * means)
        stds = np.sqrt(np.maximum(vars_, 0.0))
    
    order = np.argsort(labels, kind="mergesort")
    lab_s = labels[order]; val_s = values[order]
    starts = np.r_[0, np.where(np.diff(lab_s) != 0)[0] + 1]
    lab_unique = lab_s[starts]; ends = np.r_[starts[1:], lab_s.size]
    
    min_map = {}; max_map = {}
    if compute_minmax and lab_s.size > 0:
        mins = np.minimum.reduceat(val_s, starts)
        maxs = np.maximum.reduceat(val_s, starts)
        min_map = {int(l): float(v) for l, v in zip(lab_unique, mins)}
        max_map = {int(l): float(v) for l, v in zip(lab_unique, maxs)}

    stats = {}
    qs = [0.05, 0.25, 0.50, 0.75, 0.95]
    for rid, st, en in zip(lab_unique, starts, ends):
        rid = int(rid)
        vals_roi = val_s[st:en]
        q05, q25, q50, q75, q95 = _quantiles(vals_roi, qs)
        iqr = float(q75 - q25)
        row = {
            "n_voxels": int(counts[rid]), "mean": float(means[rid]), "std": float(stds[rid]),
            "p05": float(q05), "q1": float(q25), "median": float(q50), "q3": float(q75), "p95": float(q95), "iqr": iqr
        }
        if compute_minmax:
            row["min"] = float(min_map.get(rid, np.nan))
            row["max"] = float(max_map.get(rid, np.nan))
        stats[rid] = row
    return stats

def parse_roi_ids(arg):
    s = (arg or "").strip().lower()
    if not s: return None
    if s == "all": return []
    return [int(x) for x in s.split(",") if x.strip()]

def write_group_modality_table(df, outdir, group, modality, as_csv):
    outdir.mkdir(parents=True, exist_ok=True)
    ext = "csv" if as_csv else "tsv"
    sep = "," if as_csv else "\t"
    out_path = outdir / f"{group}_{modality}_roi_stats.{ext}"
    df.to_csv(out_path, sep=sep, index=False)
    return out_path

# ... (Plotting function same as before, omitted for brevity but assumed present) ...
def plot_single_roi_distribution(values, roi_id, roi_name, hemi, stats, out_png, modality_label, max_points):
    import matplotlib
    matplotlib.use("Agg")
    import matplotlib.pyplot as plt
    # ... (Standard plotting code) ...
    fig, ax = plt.subplots(figsize=(5, 6))
    ax.boxplot([values], showfliers=False)
    ax.set_title(f"{roi_name} ({hemi})")
    fig.savefig(out_png, dpi=100)
    plt.close(fig)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--out-root", required=True)
    parser.add_argument("--labels", default="")
    parser.add_argument("--labels-table", default="")
    parser.add_argument("--modalities", default="T1map,UNIT1")
    parser.add_argument("--outdir", default="")
    parser.add_argument("--csv", action="store_true")
    parser.add_argument("--lr-offset", type=int, default=2000)
    parser.add_argument("--right-suffix", default="_R")
    parser.add_argument("--left-suffix", default="_L")
    parser.add_argument("--include-negative", action="store_true")
    parser.add_argument("--no-minmax", action="store_true")
    parser.add_argument("--per-roi-png", action="store_true")
    parser.add_argument("--roi-ids", default="")
    parser.add_argument("--roi-png-max", type=int, default=0)
    args = parser.parse_args()

    out_root = Path(args.out_root).resolve()
    script_dir = Path(__file__).resolve().parent

    # UPDATED DEFAULT PATH: resources
    labels_path = Path(args.labels).resolve() if args.labels else (script_dir / "resources/100_AMBA_LR.nii.gz")
    table_path = Path(args.labels_table).resolve() if args.labels_table else (script_dir / "resources/allen_labels_table.csv")

    if not labels_path.exists(): raise FileNotFoundError(f"Missing labels: {labels_path}")
    
    id_to_name = {}
    if table_path.exists(): id_to_name = load_label_table(table_path)

    modalities = [m.strip() for m in args.modalities.split(",") if m.strip()]
    template_list = discover_templates(out_root, modalities)
    
    if not template_list:
        print("No templates found. Checked derivatives/templates/ and derivatives/Brain_extracted/.../To_Template/")
        return

    outdir = Path(args.outdir).resolve() if args.outdir else (out_root / "derivatives" / "ROI_stats")
    
    lab_img = nib.load(str(labels_path))
    lab_data = np.asanyarray(lab_img.get_fdata()).astype(np.int32)
    roi_ids_present = np.unique(lab_data[lab_data!=0]).tolist()
    roi_req = parse_roi_ids(args.roi_ids)

    for group, modality, tpl_path in template_list:
        tpl_data = nib.load(str(tpl_path)).get_fdata()
        stats_map = compute_stats_fast(lab_data, tpl_data, args.include_negative, not args.no_minmax)
        
        rows = []
        for roi_id in roi_ids_present:
            base, hemi, name = label_name_from_id(roi_id, id_to_name, args.lr_offset, args.right_suffix, args.left_suffix)
            s = stats_map.get(roi_id, {})
            rows.append({
                "Group": group, "Modality": modality, "ROI_id": roi_id, "ROI_name": name, "Hemisphere": hemi,
                "n_voxels": s.get("n_voxels", 0), "mean": s.get("mean"), "std": s.get("std")
            })
        
        df = pd.DataFrame(rows)
        write_group_modality_table(df, outdir / group, group, modality, args.csv)
        print(f"[OK] Stats for {group} {modality}")

if __name__ == "__main__":
    main()